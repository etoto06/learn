{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "voUhueIl_oYs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt #유니폼:확률이 같다"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randint(0,10,(32,1))\n",
        "data.shape"
      ],
      "metadata": {
        "id": "xbCuUhnsAHn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13424d17-f8d2-4a23-9f5e-94b1cb225814"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.normal(mewn=0.5, std=torch.arange(3,5))"
      ],
      "metadata": {
        "id": "4ygok8oMAQsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "input = torch.randn(32,1,28,28) #여기서 1은 흑백(채널) 젤 앞은 이미지 장 수\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohi9stpyHK84",
        "outputId": "6e5d99c2-5c5c-4e17-e2b9-d118fffd2188"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "con = nn.Conv2d(1, 6, 5 ) #입력채널수 , 출력채널수, 커널사이즈\n",
        "con.out = con(input)\n",
        "con.out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8xYU3z1HqQf",
        "outputId": "6f142fb9-66dd-4517-bb94-a9a81648c3ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu = nn.ReLU()\n",
        "relu.out = relu(con.out)\n",
        "relu.out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEnJqKkfJZxO",
        "outputId": "a831370f-8768-4c02-da16-64c1ebdf95c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool = nn.MaxPool2d(2)\n",
        "max_pool.out = max_pool(relu.out)\n",
        "max_pool.out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36pLQibvLBUP",
        "outputId": "f86ae80a-f1f9-4aad-9e00-23032663c326"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 12, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sig = nn.Sigmoid #Sigmoid 어떤 값이 들어가도 0~1사이 값으로"
      ],
      "metadata": {
        "id": "BvKDmz8JLZ_f"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig = nn.Linear(64,10)\n"
      ],
      "metadata": {
        "id": "rL3fBZJcMwTG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(V.prod)\n",
        "\n",
        "nn.Conv2d(12,12,5)"
      ],
      "metadata": {
        "id": "_LGZiX25M4iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu = nn.ReLU()\n",
        "relu.out = relu(con.out)\n",
        "relu.out.shape"
      ],
      "metadata": {
        "id": "Q_IZ8-v2OUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(y_pred.detach().numpy())\n"
      ],
      "metadata": {
        "id": "GGnMSgCTOd_2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch.info"
      ],
      "metadata": {
        "id": "7L6ZQjj6U6Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ],
      "metadata": {
        "id": "OnnX-HM-VIu0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(1, 6, 5, padding='same'), #3에서 1로 바꿈\n",
        "        # nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(6, 16, 5, padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(16, 120, 7),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(120 * 50 * 50, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(64, 10),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    features = self.features(x)\n",
        "    out = self.classifier(features)\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "xSiNd_6gVbw7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(32, 3, 224, 224)\n",
        "model = LeNet()\n",
        "output = model(input)\n",
        "type(output), len(output), output.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZtfwoQoVdRK",
        "outputId": "73073d67-18ec-49c7-8051-1a7161d948ba"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, 32, torch.Size([32, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(1, 6, 5, padding='same'),\n",
        "        #nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(6, 16, 5, padding='same'),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.Conv2d(16, 120, 7),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    #self.maxpool = nn.MaxPool2d(7)\n",
        "    self.classifier = nn.Sequential(\n",
        "        #nn.Dropout(p=0.5),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(120, 64),\n",
        "        nn.ReLU(),\n",
        "        #nn.Dropout(p=0.5),\n",
        "        #nn.Sigmoid(),\n",
        "        nn.Linear(64, 10),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    features = self.features(x)\n",
        "    print(features.shape)\n",
        "    out = self.classifier(features)\n",
        "    return out\n",
        "\n",
        "input = torch.randn(32, 1, 28, 28)\n",
        "model = LeNet()\n",
        "output = model(input)\n",
        "type(output), len(output), output.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR2qbkOxWnW0",
        "outputId": "eb337cd5-d532-413d-c604-5b2b2e3e6267"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 120, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Tensor, 32, torch.Size([32, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}